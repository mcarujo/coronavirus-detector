{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libs and setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    AvgPool2D,\n",
    "    MaxPool2D,\n",
    ")\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "\n",
    "def plot_dists(df, labels):\n",
    "    row = 1\n",
    "    col = 1\n",
    "    num_graphs = len(labels)\n",
    "    rows = math.ceil(num_graphs / 2)\n",
    "    fig = make_subplots(rows=rows, cols=2, subplot_titles=labels)\n",
    "\n",
    "    index = []\n",
    "    for row in range(1, rows + 1):\n",
    "        for col in range(1, 3):\n",
    "            index.append({\"row\": row, \"col\": col})\n",
    "\n",
    "    graphs = []\n",
    "    pos_g = 0\n",
    "    for label in labels:\n",
    "        local_data = df[label].value_counts()\n",
    "        x = list(local_data.index)\n",
    "        y = list(local_data)\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=x, y=y, text=y, textposition=\"auto\",),\n",
    "            row=index[pos_g][\"row\"],\n",
    "            col=index[pos_g][\"col\"],\n",
    "        )\n",
    "        pos_g = pos_g + 1\n",
    "    \n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=200*rows,\n",
    "        margin=dict(\n",
    "            l=50,\n",
    "            r=50,\n",
    "            b=100,\n",
    "            t=100,\n",
    "            pad=4\n",
    "        ),\n",
    "#         paper_bgcolor=\"LightSteelBlue\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "## Summary\n",
    "To explain the labels and counts of the dataset (metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(DATASET_DIR + \"Chest_xray_Corona_dataset_Summary.csv\").drop(\n",
    "    \"Unnamed: 0\", axis=1\n",
    ")\n",
    "summary.fillna(\"Not Applicable\", inplace=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_DIR + \"Chest_xray_Corona_Metadata.csv\").drop(\n",
    "    \"Unnamed: 0\", axis=1\n",
    ")\n",
    "dataset.fillna(\"Not Applicable\", inplace=True)\n",
    "dataset.Dataset_type.value_counts()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dists(\n",
    "    dataset,\n",
    "    [\"Label\", \"Dataset_type\", \"Label_2_Virus_category\", \"Label_1_Virus_category\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving to another directory \n",
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "## Normal\n",
    "fill = (dataset.Label == \"Normal\") & (dataset.Dataset_type == \"TRAIN\")\n",
    "target_path = DATASET_DIR + \"dataset/normal/\"\n",
    "origin_path = DATASET_DIR + \"train/\"\n",
    "os.makedirs(target_path, exist_ok=True)\n",
    "for x in dataset[fill].X_ray_image_name.values:\n",
    "    shutil.move(origin_path + x, target_path + x)\n",
    "    \n",
    "## Normal\n",
    "fill = (dataset.Label == \"Normal\") & (dataset.Dataset_type == \"TEST\")\n",
    "target_path = DATASET_DIR + \"dataset/normal/\"\n",
    "origin_path = DATASET_DIR + \"test/\"\n",
    "for x in dataset[fill].X_ray_image_name.values:\n",
    "    shutil.move(origin_path + x, target_path + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pnemonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill = (dataset.Label == \"Pnemonia\") & (dataset.Dataset_type == \"TRAIN\")\n",
    "target_path = DATASET_DIR + \"dataset/pnemonia/\"\n",
    "origin_path = DATASET_DIR + \"train/\"\n",
    "os.makedirs(target_path, exist_ok=True)\n",
    "for x in dataset[fill].X_ray_image_name.values:\n",
    "    shutil.move(origin_path + x, target_path + x)\n",
    "    \n",
    "fill = (dataset.Label == \"Pnemonia\") & (dataset.Dataset_type == \"TEST\")\n",
    "target_path = DATASET_DIR + \"dataset/pnemonia/\"\n",
    "origin_path = DATASET_DIR + \"test/\"\n",
    "os.makedirs(target_path, exist_ok=True)\n",
    "for x in dataset[fill].X_ray_image_name.values:\n",
    "    shutil.move(origin_path + x, target_path + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "plt.title(images[\"TRAIN\"]['Y'][sample])\n",
    "_ = plt.imshow(images[\"TRAIN\"]['X'][sample], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 1344\n",
    "plt.title(images[\"TRAIN\"][\"Y\"][sample])\n",
    "_ = plt.imshow(images[\"TRAIN\"][\"X\"][sample], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_W = 150\n",
    "IMG_H = 150\n",
    "CHANNELS = 3\n",
    "\n",
    "INPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\n",
    "NB_CLASSES = 2\n",
    "EPOCHS = 48\n",
    "BATCH_SIZE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(250, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(AvgPool2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(AvgPool2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(256, (2, 2)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=(IMG_H, IMG_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=(IMG_H, IMG_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training_accuracy\", history.history['accuracy'][-1])\n",
    "print(\"validation_accuracy\", history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= model.predict(validation_generator)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (validation_generator.class_indices)\n",
    "labels2 = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels2[k] for k in predicted_class_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(predicted_class_indices,label)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_series = pd.Series(label)\n",
    "pred_series = pd.Series(predicted_class_indices)\n",
    "pd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(cf)\n",
    "plt.title('Confusion Matrix Plot')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=80000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "X_train, X_train_lr, y_train, y_train_lr = train_test_split(X_train,\n",
    "                                                            y_train,\n",
    "                                                            test_size=0.5)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=20, activation='relu'))\n",
    "    model.add(Dense(40, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "keras_model = build_model()\n",
    "keras_model.fit(X_train, y_train, epochs=5, batch_size=100, verbose=1)\n",
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = keras_model.predict(X_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Supervised transformation based on random forests\n",
    "rf = RandomForestClassifier(max_depth=3, n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Covid (area = {:.3f})'.format(auc_keras))\n",
    "plt.plot(fpr_rf, tpr_rf, label='Normal (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
